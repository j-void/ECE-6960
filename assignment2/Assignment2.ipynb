{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 (100 points)\n",
    "\n",
    "You are expected to complete this notebook with lines of code, plots and texts. You might need to create new cells with original code or text for your analyses. This assignment has a total of 100 points.\n",
    "\n",
    "For assignment submission, you will submit this notebook file (.ipynb) on Canvas with cells executed and outputs visible. Your submitted notebook **must** follow these guidelines:\n",
    "- No other dataset than the provided datasets should be used.\n",
    "- Training, validation and testing splits should be the same as the ones provided.\n",
    "- The cell outputs in your delivered notebook should be reproducible.\n",
    "- Printing out the evaluation metric evidence that your model achieves the evaluation requirement. Optionally, you can also add plot of the evaluation metric changing over the course of training process.\n",
    "- Providing code associated with the conclusions you make in your analysis as well as code that is used to generated plot, images, etc. for your analysis.\n",
    "- All code must be your own work. Code cannot be copied from external sources or another students. You may copy code from cells that are pre-defined in this notebook if you think it is useful to reuse in another question.\n",
    "- All images must be generated from data generated in your code. Do **NOT** import/display images that are generated outside your code.\n",
    "- Your analysis must be your own, but if you quote text or equations from another source please make sure to cite the appropriate references.\n",
    "- Your input with code will be marked with comments ``###your code starts here###`` and ``###your code ends here###`` to specify where you need to write your code. You can also create a new code cell in between those marked comments.\n",
    "\n",
    "\n",
    "**NOTES:**\n",
    "- PyTorch needs to be downloaded and installed properly.\n",
    "- You should use PyTorch 1.7 or later.\n",
    "- If you need to import a different package than the ones already imported, please check with the TA if you can do so.\n",
    "- Cells should be run in order, using Shift+Enter.\n",
    "- Read all the provided code cells and comments as they contain variables and information that you may need to use to complete the notebook.\n",
    "- To create a new text cell, select \"+\" button on the menu bar and change its type from \"Code\" to \"Markdown\".\n",
    "- To modify a text cell, double click on it.\n",
    "- More details on how to format markdown text can be found here: https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\n",
    "- Your home directory on CADE machines has a small disk quota. It might be necessary, depending on how much your home directory is already occupied, to store the virtual environment inside a folder in ```/scratch/tmp/```. \n",
    "- **The accuracy requirement for each question is there to make sure you have performed sufficient amount of experiments to achieve a good result. Part of the grade is based on this.**\n",
    "\n",
    "**Tips for training deep learning models:**\n",
    "- Since the datasets being used here are small, you are probably going to have to use early stopping to prevent overfitting. This means that you will have to save your models in the middle of training. One of the ways to do so is to make a deep copy of it using ```copy.deepcopy``` function. \n",
    "- It is recommended to frequently monitor the behavior of the model at least once every epoch. You can either print out the training loss or evaluation metric of the training set to verify that the model is being optimized correctly. In this assignment, it should take somewhere between 1 and 20 epochs for a desired model to achieve the required accuracy.\n",
    "- To search for the best hyperparameters for your model, it is usually better to start searching in a logarithmic scale. Usually power of 2 or 10 is used. \n",
    "- In https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2, an ablation study in finding optimal learning rates for different optimizers are listed. This could help in your search of optimal learning rate. For this assignment, you will probably get the best results with Adam optimizer and searching for the best learning rate in the range of learning rates provided in that article, which is from 0.00005 to 0.01 unless a question is asked to use a specific optimizer.\n",
    "- Batch size seems to have a smaller impact than learning rate in the results. It should be enough if you test batch sizes between 8 and 32.\n",
    "- We assume a GPU of at least 4GB of memory is available. If you want to try running the assignment with a GPU that has less than that, you can try changing the argument passed when calling the ```define_gpu_to_use``` function.  If you are getting out-of-memory errors for the GPU, you may want to check what is occupying the GPU memory by using the command ```!nvidia-smi```, which gives a usage report of the GPU. However, if you are using your own Windows machine, the nvidia-smi command used in the define_gpu_to_use function will not work. You can skip running this function but please check to make sure your GPU has a sufficient amount of free memory.\n",
    "- For some of the questions, it might be useful for you to understand what the ResNet-18 PyTorch model is doing. You can have access to its source code here (https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py). The most important part you should know is the ```forward``` function from the ```ResNet``` class. \n",
    "- It might also be useful to print PyTorch models using ```print(\"model_name\")```. This should give you a list of all the layers in the model.\n",
    "- Here are a few PyTorch details not to forget:\n",
    "    - Toggle train/eval mode for your model\n",
    "    - Reset the gradients with ```zero_grad()``` before each call to ```backward()```\n",
    "    - Check if the loss you are using receives logits or probabilities, and adapt your model output accordingly.\n",
    "    - Reinstantiate your model every time you are starting a new training so that the weights are reset, if you plan to reuse the variable name.\n",
    "    - Pass the model's parameters to the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0 - Set-up Infrastructure (Total of 0 points)\n",
    "## + Install Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /home/sci/janmesh/anaconda3/envs/dl/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/sci/janmesh/anaconda3/envs/dl/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/sci/janmesh/anaconda3/envs/dl/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/sci/janmesh/anaconda3/envs/dl/lib/python3.10/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/sci/janmesh/anaconda3/envs/dl/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sci/janmesh/anaconda3/envs/dl/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q kaggle\n",
    "!pip3 install pydicom\n",
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import tarfile\n",
    "import time\n",
    "from packaging import version\n",
    "%matplotlib inline\n",
    "\n",
    "##### Check Torch library requirement #####\n",
    "my_torch_version = torch.__version__\n",
    "minimum_torch_version = '1.7'\n",
    "if version.parse(my_torch_version) < version.parse(minimum_torch_version):\n",
    "    print('Warning!!! Your Torch version %s does NOT meet the minimum requirement!\\\n",
    "            Please update your Torch library\\n' %my_torch_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + Create Data Folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Check what kind of system you are using #####\n",
    "try:\n",
    "    hostname = !hostname\n",
    "    if 'lab' in hostname[0] and '.eng.utah.edu' in hostname[0]:\n",
    "        IN_CADE = True\n",
    "        print(\"Cade running successfully\")\n",
    "    else:\n",
    "        IN_CADE = False\n",
    "except:\n",
    "    IN_CADE = False\n",
    "\n",
    "## Define the folders where datasets will be\n",
    "machine_being_used = 'cade' if IN_CADE else ('other')\n",
    "pre_folder = '/scratch/tmp/' if machine_being_used == 'cade' else './'\n",
    "mnist_dataset_folder = pre_folder + 'deep_learning_datasets_ECE_6960_013/mnist'\n",
    "xray14_dataset_folder = pre_folder + 'deep_learning_datasets_ECE_6960_013/chestxray14'\n",
    "\n",
    "## Create directory if they haven't existed yet \n",
    "if not os.path.exists(mnist_dataset_folder):\n",
    "    os.makedirs(mnist_dataset_folder)    \n",
    "if machine_being_used != 'cade' and not os.path.exists(mnist_dataset_folder+'/MNIST'):        \n",
    "    os.makedirs(mnist_dataset_folder+'/MNIST')\n",
    "if machine_being_used != 'cade' and not os.path.exists(mnist_dataset_folder+'/MNIST/raw'):\n",
    "    os.makedirs(mnist_dataset_folder+'/MNIST/raw')\n",
    "if not os.path.exists(xray14_dataset_folder):\n",
    "    os.makedirs(xray14_dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + Request GPU Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen GPU: 0\n"
     ]
    }
   ],
   "source": [
    "##### Request a GPU #####\n",
    "## This function locates an available gpu for usage. In addition, this function reserves a specificed\n",
    "## memory space exclusively for your account. The memory reservation prevents the decrement in computational\n",
    "## speed when other users try to allocate memory on the same gpu in the shared systems, i.e., CADE machines. \n",
    "## Note: If you use your own system which has a GPU with less than 4GB of memory, remember to change the \n",
    "## specified mimimum memory.\n",
    "def define_gpu_to_use(minimum_memory_mb = 3500):    \n",
    "    thres_memory = 600 #\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader        \n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        \n",
    "        if free_memory>minimum_memory_mb-thres_memory:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "            \n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' + str(minimum_memory_mb) \\\n",
    "              + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-thres_memory)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()        \n",
    "        del x\n",
    "        \n",
    "## Request a gpu and reserve the memory space\n",
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + Define Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Preprocess Image #####\n",
    "## This function is used to crop the largest 1:1 aspect ratio region of a given image.\n",
    "## This is useful, especially for medical datasets, since many datasets have images\n",
    "## with different aspect ratios and this is one way to standardize inputs' size.\n",
    "class CropBiggestCenteredInscribedSquare(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        longer_side = min(tensor.size)\n",
    "        horizontal_padding = (longer_side - tensor.size[0]) / 2\n",
    "        vertical_padding = (longer_side - tensor.size[1]) / 2\n",
    "        return tensor.crop(\n",
    "            (\n",
    "                -horizontal_padding,\n",
    "                -vertical_padding,\n",
    "                tensor.size[0] + horizontal_padding,\n",
    "                tensor.size[1] + vertical_padding\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Split a dataset for training, validatation, and testing #####\n",
    "## This function splits a given dataset into 3 subsets of 60%-20%-20% for train-val-test, respectively.\n",
    "## This function is used internally in the dataset classes below.\n",
    "def get_split(array_to_split, split):\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(array_to_split)\n",
    "    np.random.seed()\n",
    "    if split == 'train':\n",
    "        array_to_split = array_to_split[:int(len(array_to_split)*0.6)]\n",
    "    elif split == 'val':\n",
    "        array_to_split = array_to_split[int(len(array_to_split)*0.6):int(len(array_to_split)*0.8)]\n",
    "    elif split == 'test':\n",
    "        array_to_split = array_to_split[int(len(array_to_split)*0.8):]\n",
    "    return array_to_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compute the number parameters (weights) #####\n",
    "## This function computes the number of learnable parameters in a Pytorch model\n",
    "def count_number_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - MNIST Dataset and CNNs (Total of 32 points)\n",
    "We begin this assignment by revisiting one of the problems from the previous assignment. Previously, we built a simple two-layer neural network to classify images containing hand-written digits. In this exercise, we are going to replace that two-layer neural network with a convolutional neural network. First, we load the images that we are going to work with into Pytorch Dataloader, and then define an evaluation metric for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A summary of MNIST dataset:\n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./deep_learning_datasets_ECE_6960_013/mnist\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./deep_learning_datasets_ECE_6960_013/mnist\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "##### Load MNIST dataset to Pytorch Dataloader #####\n",
    "## Dowloand MNIST dataset train set from Pytorch (60,000 images total)\n",
    "mnist_training_data = torchvision.datasets.MNIST(mnist_dataset_folder, train = True, \\\n",
    "                                        transform=transforms.ToTensor(), \\\n",
    "                                        target_transform=None, \\\n",
    "                                        download= True)\n",
    "print('A summary of MNIST dataset:\\n')\n",
    "print(mnist_training_data,'\\n')\n",
    "## Dowloand MNIST dataset test set from Pytorch (10,000 images total)\n",
    "mnist_test_data = torchvision.datasets.MNIST(mnist_dataset_folder, train = False, \\\n",
    "                                        transform=transforms.ToTensor(), \\\n",
    "                                        target_transform=None, \\\n",
    "                                        download= True)\n",
    "print(mnist_test_data)\n",
    "## Randomly split training images into 80%/20% for training/validation process\n",
    "train_data_ex1, val_data_ex1 = torch.utils.data.random_split(mnist_training_data, \\\n",
    "                                    [int(0.8*len(mnist_training_data)),\\\n",
    "                                     len(mnist_training_data)-int(0.8*len(mnist_training_data))], \\\n",
    "                                     generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "assert(len(mnist_test_data) == 10000)\n",
    "assert(len(train_data_ex1)+len(val_data_ex1) == 60000)\n",
    "\n",
    "## Load files to Pytorch dataloader for training, validation, and testing\n",
    "train_loader_ex1 = torch.utils.data.DataLoader(train_data_ex1, batch_size=16, shuffle=True, num_workers=8)\n",
    "val_loader_ex1 = torch.utils.data.DataLoader(val_data_ex1, batch_size=128, shuffle=True, num_workers=8)\n",
    "test_loader_ex1 = torch.utils.data.DataLoader(mnist_test_data, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compute accuracy for MNIST dataset #####\n",
    "def get_accuracy_mnist(model, data_loader):\n",
    "    ## Toggle model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    ## Iterate through the dataset and perform inference for each sample.\n",
    "    ## Store inference results and target labels for AUC computation \n",
    "    with torch.no_grad():\n",
    "        #run through several batches, does inference for each and store inference results\n",
    "        # and store both target labels and inferenced scores\n",
    "        acc = 0.0\n",
    "        for image, target in data_loader:\n",
    "            image = image.cuda(); target = target.cuda()\n",
    "            probs = model(image)\n",
    "            preds = torch.argmax(probs, 1)\n",
    "            acc += torch.count_nonzero(preds == target)\n",
    "                \n",
    "        return acc/len(data_loader.dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your task is to implement a convolutional neural network, named ``model_ex1``, with the following order and set-up:\n",
    "- Zero padding the image boundaries with 2 additional pixels\n",
    "- Convolution Layer 1 - kernel size = 5; output features = 6; padding = 0; stride = 1; containing bias\n",
    "- Relu Activation Function\n",
    "- Max Pooling Layer 1 - kernel size = 2; stride = 2\n",
    "- Convolution Layer 2 - kernel size = 5; output features = 16; padding = 0; stride = 1; containing bias\n",
    "- Relu Activation Function\n",
    "- Max Pooling Layer 2 - kernel size = 2; stride = 2\n",
    "- Convolution Layer 3 - kernel size = 5; output features = 120; padding = 0; stride = 1; containing bias\n",
    "- Relu Activation Function\n",
    "- Fully-connected Layer 1 - input features = 120; output features = 84; containing bias\n",
    "- Drop-out Layer - with dropout probability of 0.5\n",
    "- Relu Activation Function\n",
    "- Fully-connected Layer 2 - input features = 84; output features = 10; containing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Implement a CNN, named model_ex1, with the architecture specified above #####\n",
    "### Your code starts here ###\n",
    "import torch.nn as nn\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x.view(x.size(0), -1)\n",
    "\n",
    "class model_ex1(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(model_ex1, self).__init__()\n",
    "  \n",
    "\t\tself.layers = nn.Sequential(\n",
    "            nn.ZeroPad2d(2),\n",
    "            \n",
    "\t\t\tnn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=0, stride=1, bias=True),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "   \n",
    "\t\t\tnn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0, stride=1, bias=True),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "   \n",
    "\t\t\tnn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, padding=0, stride=1, bias=True),\n",
    "\t\t\tnn.ReLU(),\n",
    "   \n",
    "\t\t\tFlatten(),\n",
    "   \n",
    "\t\t\tnn.Linear(120, 84),\n",
    "\t\t\tnn.Dropout(0.5),\n",
    "\t\t\tnn.ReLU(),\n",
    "   \n",
    "\t\t\tnn.Linear(84, 10)\n",
    "\t\t\t\n",
    "\t\t)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.layers(x)\n",
    "\n",
    "## Some Test Code\n",
    "# m = model_ex1()\n",
    "# input_ = torch.zeros(1,1,28,28)\n",
    "# output_ = m(input_)\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will implement the training process for ``model_ex1`` using stochastic gradient descent algorithm to optimize the softmax cross-entropy loss function. Your best trained model must meet the following requirements:\n",
    "- Your best model should be named ``best_model_ex1``.\n",
    "- Obtaining at least 98.5\\% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def weight_init(module, initf):\n",
    "\tdef foo(m):\n",
    "\t\tclassname = m.__class__.__name__.lower()\n",
    "\t\tif isinstance(m, module):\n",
    "\t\t\tinitf(m.weight)\n",
    "\treturn foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss after 0 epochs = 1.8888065814971924\n",
      "Train accuracy=0.8492082953453064, Val accuracy=0.8505833148956299\n",
      "Train Loss after 1 epochs = 1.6367112398147583\n",
      "Train accuracy=0.8671249747276306, Val accuracy=0.8700833320617676\n",
      "Train Loss after 2 epochs = 1.6131715774536133\n",
      "Train accuracy=0.8733958005905151, Val accuracy=0.8733333349227905\n",
      "Train Loss after 3 epochs = 1.583055019378662\n",
      "Train accuracy=0.9586458206176758, Val accuracy=0.9589999914169312\n",
      "Train Loss after 4 epochs = 1.522063970565796\n",
      "Train accuracy=0.9644374847412109, Val accuracy=0.9667499661445618\n",
      "Train Loss after 5 epochs = 1.5125211477279663\n",
      "Train accuracy=0.9706458449363708, Val accuracy=0.9710833430290222\n",
      "Train Loss after 6 epochs = 1.5068386793136597\n",
      "Train accuracy=0.9728749990463257, Val accuracy=0.9716666340827942\n",
      "Train Loss after 7 epochs = 1.5024651288986206\n",
      "Train accuracy=0.9742082953453064, Val accuracy=0.9739999771118164\n",
      "Train Loss after 8 epochs = 1.499698281288147\n",
      "Train accuracy=0.9762916564941406, Val accuracy=0.9749166369438171\n",
      "Train Loss after 9 epochs = 1.4974303245544434\n",
      "Train accuracy=0.9761041402816772, Val accuracy=0.9763333201408386\n",
      "Train Loss after 10 epochs = 1.4951831102371216\n",
      "Train accuracy=0.9780416488647461, Val accuracy=0.9764166474342346\n",
      "Train Loss after 11 epochs = 1.492906928062439\n",
      "Train accuracy=0.9794999957084656, Val accuracy=0.9768333435058594\n",
      "Train Loss after 12 epochs = 1.491496205329895\n",
      "Train accuracy=0.9788958430290222, Val accuracy=0.9772499799728394\n",
      "Train Loss after 13 epochs = 1.4895859956741333\n",
      "Train accuracy=0.981124997138977, Val accuracy=0.9792500138282776\n",
      "Train Loss after 14 epochs = 1.488858699798584\n",
      "Train accuracy=0.9826250076293945, Val accuracy=0.9800000190734863\n",
      "Train Loss after 15 epochs = 1.4874789714813232\n",
      "Train accuracy=0.9827708005905151, Val accuracy=0.981333315372467\n",
      "Train Loss after 16 epochs = 1.486319661140442\n",
      "Train accuracy=0.9819999933242798, Val accuracy=0.9797499775886536\n",
      "Train Loss after 17 epochs = 1.486003041267395\n",
      "Train accuracy=0.9839999675750732, Val accuracy=0.9809166789054871\n",
      "Train Loss after 18 epochs = 1.4847067594528198\n",
      "Train accuracy=0.9850624799728394, Val accuracy=0.9818333387374878\n",
      "Train Loss after 19 epochs = 1.4841982126235962\n",
      "Train accuracy=0.9845625162124634, Val accuracy=0.981333315372467\n",
      "Train Loss after 20 epochs = 1.483307957649231\n",
      "Train accuracy=0.9857708215713501, Val accuracy=0.9821666479110718\n",
      "Train Loss after 21 epochs = 1.4824382066726685\n",
      "Train accuracy=0.9836249947547913, Val accuracy=0.9806666374206543\n",
      "Train Loss after 22 epochs = 1.4823951721191406\n",
      "Train accuracy=0.9853333234786987, Val accuracy=0.9828333258628845\n",
      "Train Loss after 23 epochs = 1.4818733930587769\n",
      "Train accuracy=0.9869583249092102, Val accuracy=0.9830833077430725\n",
      "Train Loss after 24 epochs = 1.4809277057647705\n",
      "Train accuracy=0.987666666507721, Val accuracy=0.984333336353302\n",
      "Train Loss after 25 epochs = 1.4805395603179932\n",
      "Train accuracy=0.9878541827201843, Val accuracy=0.9828333258628845\n",
      "Train Loss after 26 epochs = 1.4801478385925293\n",
      "Train accuracy=0.9871875047683716, Val accuracy=0.9829999804496765\n",
      "Train Loss after 27 epochs = 1.479533314704895\n",
      "Train accuracy=0.9887291789054871, Val accuracy=0.984416663646698\n",
      "Train Loss after 28 epochs = 1.478761076927185\n",
      "Train accuracy=0.9887916445732117, Val accuracy=0.9838333129882812\n",
      "Train Loss after 29 epochs = 1.478115200996399\n",
      "Train accuracy=0.9889166355133057, Val accuracy=0.9856666326522827\n",
      "Accuracy of 98.5% reached - stopping model\n"
     ]
    }
   ],
   "source": [
    "##### Training Process #####\n",
    "### Your code starts here ###\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "model_ex1_1 = model_ex1()\n",
    "model_ex1_1.to(DEVICE)\n",
    "model_ex1_1.apply(weight_init(module=nn.Conv2d, initf=nn.init.kaiming_uniform_))\n",
    "model_ex1_1.apply(weight_init(module=nn.Linear, initf=nn.init.kaiming_uniform_))\n",
    "num_epochs = 100\n",
    "\n",
    "optimizer = torch.optim.SGD(model_ex1_1.parameters(), lr=1e-2)\n",
    "optimizer.zero_grad()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "prev_acc = 0\n",
    "\n",
    "save_dir = os.path.join(pre_folder, \"save_model_ex1_1\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_ex1_1.train()\n",
    "    loss_dict = defaultdict(list)\n",
    "    for image, labels in train_loader_ex1:\n",
    "        optimizer.zero_grad()\n",
    "        image = image.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        output = torch.softmax(model_ex1_1(image), dim=1)\n",
    "        final_loss = criterion_ce(output, labels)\n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_dict[\"ce\"].append(final_loss.detach().cpu())\n",
    "    \n",
    "    print(f'Train Loss after {epoch} epochs = {np.mean(np.array(loss_dict[\"ce\"]))}')\n",
    "    train_acc = get_accuracy_mnist(model_ex1_1, train_loader_ex1)\n",
    "    val_acc = get_accuracy_mnist(model_ex1_1, val_loader_ex1)\n",
    "    print(f'Train accuracy={train_acc}, Val accuracy={val_acc}')\n",
    "    \n",
    "    if val_acc > prev_acc:\n",
    "        torch.save(model_ex1_1.state_dict(), os.path.join(save_dir, \"model_best.torch\"))\n",
    "        prev_acc = val_acc\n",
    "    \n",
    "    if val_acc > 0.985:\n",
    "        print(\"Accuracy of 98.5% reached - stopping model\")\n",
    "        best_model_ex1 = copy.deepcopy(model_ex1_1)\n",
    "        break\n",
    "    \n",
    "    if epoch != 0 and epoch % 10 == 0:\n",
    "        scheduler.step()\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we are going to evaluate your best trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Test Accuracy: 98.640%\n"
     ]
    }
   ],
   "source": [
    "##### Inference stage for MNIST dataset #####\n",
    "test_acc = get_accuracy_mnist(best_model_ex1, test_loader_ex1)\n",
    "print('MNIST Test Accuracy: %.3f%%' %(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - ChestXray14 Dataset (Total of 68 points)\n",
    ">### Brief explanation of the dataset\n",
    "> The ChestXray14 dataset contains more than 100,000 frontal chest x-rays and labels for 14 different conditions. These labels were extracted from radiologists' reports associated with each image using natural language processing techniques. It was released at the end of 2017 and was the largest publicly available x-rays dataset for developing deep learning models at the time. More information about the ChestXray14 dataset can be found here: https://stanfordmlgroup.github.io/projects/chexnet/. \n",
    "\n",
    "In this exercise, we will be using only a subset of this dataset, 14,999 images in total. The labels of this dataset follow a multi-label structure, which means that each image can have more than one label. First, we need to obtain the dataset. Please download the file **Data_Entry_2017_v2020.csv** from https://nihcc.app.box.com/v/ChestXray-NIHCC and **image_names_chestxray14.csv** from Canvas, and put them in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download part of the dataset if it was not downloaded yet and \n",
    "## put it to the xray14_dataset_folder folder\n",
    "\n",
    "##### Report download status #####\n",
    "def report_hook(count_so_far, block_size, total_size):\n",
    "    current_percentage = (count_so_far * block_size * 100 // total_size)\n",
    "    previous_percentage = ((count_so_far - 1) * block_size * 100 // total_size)\n",
    "    if current_percentage != previous_percentage:\n",
    "        sys.stdout.write('\\r' + str((count_so_far * block_size * 100 // total_size)) \\\n",
    "                         + '% of download completed')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "##### Download a subset of ChestXray14 dataset #####        \n",
    "if xray14_dataset_folder != '/scratch/tmp/deep_learning_datasets_ECE_6960_013/chestxray14':\n",
    "    os.makedirs(xray14_dataset_folder, exist_ok=True)\n",
    "    from urllib.request import urlretrieve\n",
    "    destination_file = xray14_dataset_folder + '/images_4.tar.gz'\n",
    "    link = 'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz'\n",
    "    if not os.path.isfile(destination_file):\n",
    "        urlretrieve(link, destination_file, reporthook = report_hook)\n",
    "\n",
    "    destination_file = xray14_dataset_folder + '/images_1.tar.gz'\n",
    "    link = 'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz'\n",
    "    if not os.path.isfile(destination_file):\n",
    "        urlretrieve(link, destination_file, reporthook = report_hook)        \n",
    "    \n",
    "##### Extract the downloaded file #####\n",
    "if xray14_dataset_folder != '/scratch/tmp/deep_learning_datasets_ECE_6960_013/chestxray14':\n",
    "    destination_file = xray14_dataset_folder + '/images_4.tar.gz'\n",
    "    tar = tarfile.open(destination_file, \"r:gz\")\n",
    "    tar.extractall(path = xray14_dataset_folder)\n",
    "    tar.close()\n",
    "    destination_file = xray14_dataset_folder + '/images_1.tar.gz'\n",
    "    tar = tarfile.open(destination_file, \"r:gz\")\n",
    "    tar.extractall(path = xray14_dataset_folder)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a Pytorch class structure for this dataset. The dataset class is used to load, index, and preprocess samples for training, validation, and testing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chestxray14Dataset(Dataset):\n",
    "    ##### Initialize the class #####\n",
    "    def __init__(self, path_dataset_folder, split = 'train'):\n",
    "        ## Split parameter is used to specify which process the data is used for,\n",
    "        ## and it can be 'train', 'val', and 'test'\n",
    "        \n",
    "        self.path_image_folder = path_dataset_folder + '/images'\n",
    "        \n",
    "        ## Get the filenames of all images in the dataset\n",
    "        all_images_list = pd.read_csv('image_names_chestxray14.csv')\n",
    "\n",
    "        ## Read the labels file which needs to be placed in the same folder as this notebook\n",
    "        label_file = pd.read_csv('./Data_Entry_2017_v2020.csv')\n",
    "        \n",
    "        ## Merge labels and images information\n",
    "        examples_to_use = pd.merge(all_images_list, label_file)\n",
    "        \n",
    "        ## This is the name of all possible labels in this dataset.\n",
    "        ## The corresponding label of each sample is an array of 14 elements in which the elements are ordered\n",
    "        ## in the same way as \"self.set_of_finding_labels\" and the value of each element represents the \n",
    "        ## presence of that condition in the sample. For example, if \"cardiomegaly\" and \"pneumonia\" are the two \n",
    "        ## conditions presence a given sample, then the corresponding label of that sample is represented \n",
    "        ## by an array  - [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "        self.set_of_finding_labels = ['Atelectasis', 'Cardiomegaly','Effusion',  'Infiltration', 'Mass',\\\n",
    "                                      'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', \\\n",
    "                                      'Emphysema', 'Fibrosis','Pleural_Thickening', 'Hernia' ]\n",
    "        \n",
    "        ## Read labels from the label file\n",
    "        examples_to_use['Finding Labels'] = examples_to_use['Finding Labels'].str.split(pat = '|')\n",
    "        examples_to_use['Finding Labels'] = examples_to_use['Finding Labels'].apply(list).\\\n",
    "                                            to_frame(name='Finding Labels')\n",
    "        for finding_label in self.set_of_finding_labels:\n",
    "            examples_to_use[finding_label] = examples_to_use.apply(\\\n",
    "                                            lambda x: int(finding_label in x['Finding Labels']), axis=1)\n",
    "        \n",
    "        ## Get the list of all patient ids present in the dataset and split into\n",
    "        ## training, validation and testing by patient id, but not by list of examples\n",
    "        patient_ids = pd.unique(examples_to_use['Patient ID'])\n",
    "        patient_ids = pd.DataFrame(get_split(patient_ids, split), columns = ['Patient ID'])\n",
    "        \n",
    "        ## Filter the examples to only use the ones that have the chosen patient ids\n",
    "        examples_to_use = pd.merge(patient_ids,examples_to_use)        \n",
    "        \n",
    "        examples_to_use = examples_to_use[['Image Index'] + self.set_of_finding_labels]\n",
    "        self.image_list = examples_to_use['Image Index'].values\n",
    "        self.targets = examples_to_use[self.set_of_finding_labels].values\n",
    "        \n",
    "        ## Define data augmentation transformations for the input images. In this exercise, we use the following\n",
    "        ## transformations: square center cropping, resizing to 224x224 (to be similar as ImageNet dataset), \n",
    "        ## converting to tensor, normalizing per channel (i.e., R, G, and B) \n",
    "        ## with the average and standard deviation of images in the ImageNet dataset        \n",
    "        self.set_of_transforms = transforms.Compose(\n",
    "        [CropBiggestCenteredInscribedSquare(),\n",
    "         transforms.Resize(224),\n",
    "         transforms.ToTensor(), \n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "        \n",
    "    ##### Retrieve a sample with the corresponding index #####\n",
    "    ## This function retrieve a sample from the dataset at the specified index \n",
    "    ## and returns an image and the corresponding label stored in Pytorch tensors     \n",
    "    def __getitem__(self, index):\n",
    "        curr_pil_image = Image.open(self.path_image_folder + '/' + self.image_list[index]).convert('RGB')\n",
    "        image_to_return = self.set_of_transforms(curr_pil_image)\n",
    "                \n",
    "        return image_to_return, torch.FloatTensor(self.targets[index])\n",
    "    \n",
    "    ##### Get the length of the dataset #####\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    ##### Access the name of conditions in the labels #####\n",
    "    def get_labels_name(self):\n",
    "        return self.set_of_finding_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use the class function above to create structures for each training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create datasets for this exercise\n",
    "train_dataset_ex2 = Chestxray14Dataset(xray14_dataset_folder)\n",
    "val_dataset_ex2 = Chestxray14Dataset(xray14_dataset_folder, split = 'val')\n",
    "test_dataset_ex2 = Chestxray14Dataset(xray14_dataset_folder, split = 'test')\n",
    "\n",
    "\n",
    "## Please contact the TA if any of the assertions fails\n",
    "assert(len(train_dataset_ex2) == 8837)\n",
    "assert(len(val_dataset_ex2) == 2924)\n",
    "assert(len(test_dataset_ex2) == 3238)\n",
    "assert(np.sum(train_dataset_ex2.targets)==5893)\n",
    "assert(np.sum(train_dataset_ex2.targets[:,7])==404)\n",
    "assert(np.sum(val_dataset_ex2.targets)==1810)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we report a statistical summary of the training set to get an idea of what this dataset looks like. We also show a sample of this dataset to get ourselves familiar with the type of images we are working with in this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper function for display text below #####\n",
    "def join_str_array_to_labels(str_array,labels):\n",
    "    return ','.join(['\\n{}: {}'.format(labels[index_element], str_array_element) \n",
    "                for index_element, str_array_element in enumerate(str_array)])\n",
    "\n",
    "## Show the statistics of training set\n",
    "frequencies = np.sum(train_dataset_ex2.targets, axis = 0)/len(train_dataset_ex2)\n",
    "text_frequencies = ['{:.2f}%'.format(frequency*100) for frequency in frequencies]                    \n",
    "print('Percentage of positive examples in each class in the training set: ')\n",
    "print(join_str_array_to_labels(text_frequencies, train_dataset_ex2.get_labels_name()))\n",
    "\n",
    "## Plot a sample from the training set\n",
    "print('\\n\\nShowing one example from the dataset:')\n",
    "plt.imshow(train_dataset_ex2[1][0].cpu().numpy()[0,:,:], cmap = 'gray')\n",
    "print(join_str_array_to_labels(train_dataset_ex2[1][1],train_dataset_ex2.get_labels_name()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use AUC (also called AUROC) metric to evaluate the performance of a model. The AUC metric is defined as the area under the Receiver Operating Characteristic (ROC) curve, and has a value between 0 and 1. An AUC of 0.5 is what a model producing random outputs can maximally achieve. The higher the AUC is the better the model. In medical related applications, we want to avoid false negatives or false positives outcomes. Thus, the ROC curve is frequently used because it measures the trade-off between false positives and false negatives (sensitivity and specificity to be precise) of a model. Besides, ROC is insensitive to imbalanced datasets. We will define this metric in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Calculate AUC metric #####\n",
    "## This function compute AUC from the given input arrays i.e., predicted value and ground truth arrays\n",
    "def auroc(logits_predicted, target):\n",
    "    fpr, tpr, _ = roc_curve(target, logits_predicted)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "##### Compute AUC of a given dataset #####\n",
    "## This function takes a model and Pytorch data loader as input. \n",
    "## The given model is used to predict the expected label for each sample in the Pytorch data loader. The \n",
    "## model output for each sample is an array with 14 elements corresponding with 14 conditions in the \n",
    "## ChestXray14 dataset. Then, the AUC is computed for each condition.\n",
    "def get_score_model_chestxray_binary_model(model, data_loader):\n",
    "    ## Toggle model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    ## Iterate through the dataset and perform inference for each sample.\n",
    "    ## Store inference results and target labels for AUC computation \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        logits_predicted = np.zeros([0, 14])\n",
    "        targets = np.zeros([0, 14])\n",
    "        ## Iterate through the dataset and perform inference for each sample.\n",
    "        ## Store inference results and target labels for AUC computation  \n",
    "        for image, target in data_loader:\n",
    "            image = image.cuda()\n",
    "            logit_predicted = model(image)\n",
    "            logits_predicted = np.concatenate((logits_predicted, logit_predicted.cpu().detach().numpy())\\\n",
    "                                              , axis = 0)\n",
    "            targets = np.concatenate((targets, target.cpu().detach().numpy()), axis = 0)\n",
    "            \n",
    "    ## Return a list of auc values in which each value corresponds to one of the 14 labels\n",
    "    return [auroc(logits_predicted[:,i], targets[:,i]) for i in range(14)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1 - Adopt an ImageNet Pretrained Model (34 points)\n",
    "In this section, you will adopt ResNet-18 pretrained on Imagenet dataset provided in the torchvision package from Pytorch library (https://pytorch.org/docs/stable/torchvision/models.html#id3) for ChestXray14 dataset. To obtain that goal, our tasks are as follows:\n",
    "- Setting up Pytorch dataloader for training, validation, and test sets\n",
    "- Modifying the ResNet-18 model to have 14 neurons, which corresponds to 14 labels, in the output layer\n",
    "- Selecting a loss function and justify your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Set-up Pytorch dataloader #####\n",
    "### Your code starts here ###\n",
    "\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Modify ResNet-18 #####\n",
    "### Your code starts here ###\n",
    "\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a short reasoning for your loss function selection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define loss function #####\n",
    "### Your code starts here ###\n",
    "\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will implement the training process for the modified ResNet-18 model. Your best trained model must achieve the mean AUC of 14 classes of at least 0.725 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training Process #####\n",
    "### Your code starts here ###\n",
    "\n",
    "    \n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the desired accuracy on the validation set, test your best model on the test set, and specify the anomalies/labels of which your model achieves best and worst AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Inference stage for ChestXray14 dataset #####\n",
    "### Your code starts here ###\n",
    "\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2 - Implement Your Own Model (34 points) \n",
    "For this exercise, you are going to build your own model for ChestXray14 dataset. Your model has to satisfy the following conditions:\n",
    "- Containing at most 500,000 learnable parameters.\n",
    "- Training your model from scratch, i.e., none of the learnable parameters in your model is extracted from another pretrained model.\n",
    "- Obtaining at least 0.67 for the mean AUC of 14 classes on the validation set.\n",
    "\n",
    "In addition to having at least one model meets the requirements above, you need to show that you have tried:\n",
    "- at least 2 other architectures, i.e., with different number of layers, different number of feature maps at each layers, different combinations of layers, etc.\n",
    "- at least 2 hyperpameters with a set of values for each hyperparameter.\n",
    "\n",
    "Describe/Analyze the experiments you perform with plots, tables, and text on what works well and what does not. Please also include the code associated with these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Implement Your Own Model #####\n",
    "### Your code starts here ###\n",
    "\n",
    "    \n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will verify if your best model meets the number of learnable parameters requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Verify the number of learnable parameters requirement #####\n",
    "## ***** Please change the parameter inside the \"count_number_parameters\" \n",
    "##       to the name of the model you want to test *****\n",
    "if count_number_parameters(best_model_ex22) > 500000:\n",
    "    print('Warning! Your model exceeds the learnable parameters requirement!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test your best model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Perform inference with your best model #####\n",
    "### Your code starts here \n",
    "\n",
    "\n",
    "### Your code ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b946a853462aecc67606b63d029da11433a0dee34bccb49aaa4b239674dbcf5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
